"""
è½¦é“çº§äº¤é€šçŠ¶å†µæ•°æ®é›†ç±»
æ”¯æŒé™æ€é“è·¯æ•°æ®(graph.json)å’ŒåŠ¨æ€äº¤é€šæ•°æ®(csv)ï¼Œä»¥åŠç”¨æˆ·è‡ªå®šä¹‰æ©ç 
"""

import numpy as np
import pandas as pd
import torch
from typing import Optional, Tuple, Union, List, Dict, Any
from pathlib import Path
import pickle
import json
from tsl.datasets import Dataset
from tsl.data import SpatioTemporalDataset
from tsl.data.preprocessing import StandardScaler
from tsl.ops.connectivity import adj_to_edge_index
from tsl.utils.python_utils import ensure_list
from ..layers import DTStateFilter


class LaneTrafficDataset(Dataset):
    """
    è½¦é“çº§äº¤é€šçŠ¶å†µæ•°æ®é›†
    
    æ•°æ®æ ¼å¼ï¼š
    - é™æ€æ•°æ®(graph.json): åŒ…å« lane_id å’Œ node_connections
    - åŠ¨æ€æ•°æ®(csv): åŒ…å« lane_id, start_frame, avg_speed, avg_occupancy ç­‰ç‰¹å¾
    - æ©ç æ•°æ®(csv): åŒ…å« start_frame, lane_id, is_observed
    
    æ”¯æŒä¸¤ç§è¾“å…¥æ–¹å¼ï¼š
    1. å•ç»„æ•°æ®ï¼šç›´æ¥ä¼ å…¥ static_data_path, dynamic_data_path, mask_data_path
    2. å¤šç»„æ•°æ®ï¼šä¼ å…¥ data_groups åˆ—è¡¨ï¼Œæ¯ç»„åŒ…å« static, dynamic, mask è·¯å¾„
    """
    
    # é»˜è®¤ç‰¹å¾åˆ—ï¼ˆå¯é…ç½®ï¼‰
    DEFAULT_FEATURE_COLS = [
        'avg_speed', 'avg_occupancy', 'total_vehicles'
    ]
    
    def __init__(self, 
                 static_data_path: Optional[str] = None,
                 dynamic_data_path: Optional[str] = None,
                 mask_data_path: Optional[str] = None,
                 data_groups: Optional[List[Dict[str, str]]] = None,
                 feature_cols: Optional[List[str]] = None,
                 time_col: str = 'start_frame',
                 lane_id_col: str = 'lane_id',
                 mask_time_col: str = 'start_frame',
                 mask_lane_col: str = 'lane_id',
                 mask_value_col: str = 'is_observed',
                 window_size: int = 10,
                 stride: int = 1,
                 val_len: float = 0.1,
                 test_len: float = 0.2,
                 impute_nans: bool = True,
                 fill_value: float = 0.0, # ç¼ºå¤±å€¼å¡«å……å€¼
                 enable_dtsf: bool = True, # æ˜¯å¦å¯ç”¨åŒæ—¶é—´å°ºåº¦æ‹¥å µéšçŠ¶æ€
                 dtsf_gamma: float = 0.7, # åŒæ—¶é—´å°ºåº¦æ‹¥å µéšçŠ¶æ€çš„gammaå‚æ•°ï¼Œè¶Šæ¥è¿‘ 1ï¼Œå†å²çŠ¶æ€å æ¯”è¶Šå¤§ï¼Œæ›²çº¿è¶Šå¹³æ»‘ã€ååº”è¶Šæ…¢
                 dtsf_delta: float = 5.0, # åŒæ—¶é—´å°ºåº¦æ‹¥å µéšçŠ¶æ€çš„deltaå‚æ•°
                 dtsf_vth_ratio: float = 0.8, # åŒæ—¶é—´å°ºåº¦æ‹¥å µéšçŠ¶æ€çš„vth_ratioå‚æ•°ï¼Œå½“é€Ÿåº¦ä½äºåŸºç¡€é€Ÿåº¦çš„è¿™ä¸ªå€¼å·¦å³å°±å¼€å§‹è¢«è®¤ä¸ºæ˜¯æ‹¥å µã€‚
                 dtsf_initial_z: float = 1.0, # åŒæ—¶é—´å°ºåº¦æ‹¥å µéšçŠ¶æ€çš„åˆå§‹æ‹¥å µçŠ¶æ€å‚æ•°
                 dtsf_v_base_init: float = 45.0, # åŒæ—¶é—´å°ºåº¦æ‹¥å µéšçŠ¶æ€çš„v_base_initå‚æ•°ï¼ŒåŸºç¡€é€Ÿåº¦çš„åˆå§‹å€¼
                 dtsf_no_car_value: Optional[float] = None,
                 dtsf_auto_no_car: bool = True, # æ˜¯å¦è‡ªåŠ¨è¯†åˆ«"æ— è½¦"æ ‡è®°å€¼
                 dtsf_treat_no_car_as_missing: bool = True, # æ˜¯å¦å°†"æ— è½¦"æ ‡è®°å€¼è§†ä¸ºç¼ºå¤±å€¼
                 dtsf_no_car_eps: float = 1e-3, # "æ— è½¦"æ ‡è®°å€¼çš„epsilonå‚æ•°
                 dtsf_device: str = 'cuda', # åŒæ—¶é—´å°ºåº¦æ‹¥å µéšçŠ¶æ€çš„è®¾å¤‡å‚æ•°
                 **kwargs):
        """
        åˆå§‹åŒ–è½¦é“çº§äº¤é€šæ•°æ®é›†
        
        Args:
            static_data_path: é™æ€é“è·¯æ•°æ®æ–‡ä»¶è·¯å¾„(graph.json)ï¼Œå•ç»„æ•°æ®æ—¶ä½¿ç”¨
            dynamic_data_path: åŠ¨æ€äº¤é€šæ•°æ®æ–‡ä»¶è·¯å¾„(csv)ï¼Œå•ç»„æ•°æ®æ—¶ä½¿ç”¨
            mask_data_path: ç”¨æˆ·è‡ªå®šä¹‰æ©ç æ–‡ä»¶è·¯å¾„(csv)ï¼Œå¯é€‰
            data_groups: å¤šç»„æ•°æ®é…ç½®åˆ—è¡¨ï¼Œæ¯ç»„æ ¼å¼ä¸º:
                         [{"static": "path1.json", "dynamic": "path1.csv", "mask": "mask1.csv"}, ...]
            feature_cols: è¦ä½¿ç”¨çš„ç‰¹å¾åˆ—ååˆ—è¡¨ï¼Œé»˜è®¤ä½¿ç”¨æ‰€æœ‰æ•°å€¼ç‰¹å¾
            time_col: åŠ¨æ€æ•°æ®ä¸­çš„æ—¶é—´åˆ—å
            lane_id_col: è½¦é“IDåˆ—å
            mask_time_col: æ©ç æ–‡ä»¶ä¸­çš„æ—¶é—´åˆ—å
            mask_lane_col: æ©ç æ–‡ä»¶ä¸­çš„è½¦é“IDåˆ—å
            mask_value_col: æ©ç æ–‡ä»¶ä¸­çš„è§‚æµ‹å€¼åˆ—å
            window_size: æ—¶é—´çª—å£å¤§å°
            stride: æ—¶é—´æ­¥é•¿
            val_len: éªŒè¯é›†æ¯”ä¾‹
            test_len: æµ‹è¯•é›†æ¯”ä¾‹
            impute_nans: æ˜¯å¦å¡«å……ç¼ºå¤±å€¼
            fill_value: ç¼ºå¤±å€¼å¡«å……å€¼
        """
        super().__init__(**kwargs)
        
        # å¤„ç†æ•°æ®è·¯å¾„ï¼šæ”¯æŒå•ç»„æˆ–å¤šç»„
        if data_groups is not None:
            self.data_groups = data_groups
        elif static_data_path is not None and dynamic_data_path is not None:
            self.data_groups = [{
                'static': static_data_path,
                'dynamic': dynamic_data_path,
                'mask': mask_data_path
            }]
        else:
            raise ValueError("å¿…é¡»æä¾› data_groups æˆ– (static_data_path + dynamic_data_path)")
        
        self.feature_cols = feature_cols or self.DEFAULT_FEATURE_COLS
        self.time_col = time_col
        self.lane_id_col = lane_id_col
        self.mask_time_col = mask_time_col
        self.mask_lane_col = mask_lane_col
        self.mask_value_col = mask_value_col
        self.window_size = window_size
        self.stride = stride
        self.val_len = val_len
        self.test_len = test_len
        self.impute_nans = impute_nans
        self.fill_value = fill_value
        self.enable_dtsf = enable_dtsf
        self.dtsf_gamma = dtsf_gamma
        self.dtsf_delta = dtsf_delta
        self.dtsf_vth_ratio = dtsf_vth_ratio
        self.dtsf_initial_z = dtsf_initial_z
        self.dtsf_v_base_init = dtsf_v_base_init
        self.dtsf_no_car_value = dtsf_no_car_value
        self.dtsf_auto_no_car = dtsf_auto_no_car
        self.dtsf_treat_no_car_as_missing = dtsf_treat_no_car_as_missing
        self.dtsf_no_car_eps = dtsf_no_car_eps
        self.dtsf_device = dtsf_device
        
        # ä¿å­˜å½’ä¸€åŒ–å‚æ•°ï¼ˆç”¨äºæ¨ç†æ—¶åå½’ä¸€åŒ–ï¼‰
        self.speed_normalization_params = None  # {'speed_min': float, 'speed_max': float, 'is_normalized': bool}
        
        # ä¿å­˜ç”¨äºè®­ç»ƒæ—¶å¾ªç¯é€‰æ‹©çš„maskæ–‡ä»¶åˆ—è¡¨ï¼ˆä»data_groupsä¸­è‡ªåŠ¨æå–ï¼‰
        self.mask_files = []  # å®é™…ä½¿ç”¨çš„maskæ–‡ä»¶åˆ—è¡¨ï¼ˆåŒ…å«åŒ¹é…ä¿¡æ¯ï¼‰
        self.current_mask_file = None  # å½“å‰ä½¿ç”¨çš„maskæ–‡ä»¶è·¯å¾„
        self.current_mask_index = 0  # å½“å‰é€‰æ‹©çš„maskæ–‡ä»¶ç´¢å¼•ï¼ˆç”¨äºå¾ªç¯é€‰æ‹©ï¼‰
        
        # åŠ è½½å’Œé¢„å¤„ç†æ•°æ®
        self._load_data()
        self._preprocess_data()
        
        # åˆå§‹åŒ–mask_filesåˆ—è¡¨ï¼ˆå¦‚æœæœªæŒ‡å®šï¼Œä»data_groupsä¸­æå–ï¼‰
        self._initialize_mask_files()
        
    def _load_data(self):
        """åŠ è½½é™æ€é“è·¯æ•°æ®å’ŒåŠ¨æ€äº¤é€šæ•°æ®ï¼ˆæ”¯æŒå¤šç»„ï¼‰"""
        self.static_nodes = []
        self.dynamic_df = pd.DataFrame()
        self.mask_data_paths = []  # ä¿å­˜æ‰€æœ‰maskè·¯å¾„ä¾›åç»­ä½¿ç”¨
        self.dynamic_file_info = []  # ä¿å­˜æ¯ä¸ªdynamicæ–‡ä»¶çš„ä¿¡æ¯ï¼ˆç”¨äºåŒ¹é…maskæ–‡ä»¶ï¼‰
        
        # ç”¨äºè®°å½•æ—¶é—´æˆ³åç§»é‡ï¼Œé¿å…ä¸åŒæ–‡ä»¶çš„æ—¶é—´æˆ³å†²çª
        time_offset = 0.0
        max_timestamp_so_far = None
        
        for i, group in enumerate(self.data_groups):
            print(f"\nğŸ“‚ åŠ è½½ç¬¬ {i+1}/{len(self.data_groups)} ç»„æ•°æ®...")
            
            # 1. åŠ è½½é™æ€é“è·¯æ•°æ® (graph.json)
            static_path = Path(group['static'])
            if static_path.suffix == '.json':
                with open(static_path, 'r', encoding='utf-8') as f:
                    static_data = json.load(f)
                if 'nodes' in static_data:
                    nodes = static_data['nodes']
                else:
                    nodes = static_data
                self.static_nodes.extend(nodes)
                print(f"   âœ… é™æ€æ•°æ®: {len(nodes)} ä¸ªèŠ‚ç‚¹")
            else:
                raise ValueError(f"é™æ€æ•°æ®æ–‡ä»¶åº”ä¸ºJSONæ ¼å¼: {static_path.suffix}")
            
            # 2. åŠ è½½åŠ¨æ€äº¤é€šæ•°æ® (csv)
            dynamic_path = Path(group['dynamic'])
            if dynamic_path.suffix == '.csv':
                df = pd.read_csv(dynamic_path)
                
                # æ£€æŸ¥æ—¶é—´æˆ³åˆ—æ˜¯å¦å­˜åœ¨
                if self.time_col not in df.columns:
                    raise ValueError(f"åŠ¨æ€æ•°æ®æ–‡ä»¶ {dynamic_path} ç¼ºå°‘æ—¶é—´åˆ—: {self.time_col}")
                
                # è·å–å½“å‰æ–‡ä»¶çš„æ—¶é—´æˆ³èŒƒå›´
                current_times = df[self.time_col].values
                current_min_time = np.min(current_times)
                current_max_time = np.max(current_times)
                time_span = current_max_time - current_min_time
                
                # åˆå§‹åŒ–å½“å‰æ–‡ä»¶çš„åç§»é‡ï¼ˆç¬¬ä¸€ä¸ªæ–‡ä»¶ä¸º0ï¼‰
                current_file_offset = 0.0
                
                # å¦‚æœè¿™ä¸æ˜¯ç¬¬ä¸€ä¸ªæ–‡ä»¶ï¼Œä¸”æ—¶é—´æˆ³æœ‰é‡å é£é™©ï¼Œåˆ™æ·»åŠ åç§»é‡
                if i > 0 and max_timestamp_so_far is not None:
                    # è®¡ç®—åç§»é‡ï¼šä¹‹å‰æœ€å¤§æ—¶é—´æˆ³ + æ—¶é—´é—´éš” + 1ï¼ˆç¡®ä¿ä¸é‡å ï¼‰
                    # æ—¶é—´é—´éš”å–å½“å‰æ–‡ä»¶çš„æ—¶é—´è·¨åº¦ï¼Œæˆ–è€…å¦‚æœæ— æ³•ç¡®å®šåˆ™ä½¿ç”¨ä¸€ä¸ªè¾ƒå¤§çš„å€¼
                    if time_span > 0:
                        # ä½¿ç”¨å½“å‰æ–‡ä»¶çš„æ—¶é—´è·¨åº¦ä½œä¸ºé—´éš”
                        time_gap = time_span * 0.1  # æ·»åŠ 10%çš„é—´éš”ä½œä¸ºç¼“å†²
                    else:
                        # å¦‚æœæ—¶é—´è·¨åº¦ä¸º0ï¼ˆæ‰€æœ‰æ—¶é—´æˆ³ç›¸åŒï¼‰ï¼Œä½¿ç”¨ä¸€ä¸ªå›ºå®šé—´éš”
                        time_gap = 1.0
                    
                    current_file_offset = max_timestamp_so_far + time_gap + 1.0
                    print(f"   â° æ£€æµ‹åˆ°æ—¶é—´æˆ³å†²çªé£é™©ï¼Œä¸ºæ–‡ä»¶ {i+1} æ·»åŠ æ—¶é—´åç§»é‡: {current_file_offset:.2f}")
                
                # åº”ç”¨æ—¶é—´åç§»é‡
                df[self.time_col] = df[self.time_col] + current_file_offset
                
                # æ›´æ–°æœ€å¤§æ—¶é—´æˆ³
                current_max_time_adjusted = current_max_time + current_file_offset
                if max_timestamp_so_far is None:
                    max_timestamp_so_far = current_max_time_adjusted
                else:
                    max_timestamp_so_far = max(max_timestamp_so_far, current_max_time_adjusted)
                
                self.dynamic_df = pd.concat([self.dynamic_df, df], ignore_index=True)
                print(f"   âœ… åŠ¨æ€æ•°æ®: {df.shape[0]} æ¡è®°å½• (æ—¶é—´èŒƒå›´: {current_min_time + current_file_offset:.2f} ~ {current_max_time_adjusted:.2f})")
            else:
                raise ValueError(f"åŠ¨æ€æ•°æ®æ–‡ä»¶åº”ä¸ºCSVæ ¼å¼: {dynamic_path.suffix}")
            
            # 3. ä¿å­˜dynamicæ–‡ä»¶ä¿¡æ¯ï¼ˆç”¨äºåŒ¹é…maskæ–‡ä»¶ï¼‰
            # åŒæ—¶è®°å½•è¯¥æ–‡ä»¶çš„æ—¶é—´æˆ³èŒƒå›´ï¼ˆå·²åº”ç”¨åç§»é‡ï¼‰ï¼Œç”¨äºåç»­ç¡®å®šæ–‡ä»¶è¾¹ç•Œ
            file_min_time = current_min_time + current_file_offset
            file_max_time = current_max_time + current_file_offset
            
            # æ”¯æŒmaskå­—æ®µæ˜¯å•ä¸ªæ–‡ä»¶è·¯å¾„æˆ–æ–‡ä»¶è·¯å¾„åˆ—è¡¨
            mask_path_or_list = group.get('mask')
            if mask_path_or_list is None:
                mask_paths = []
            elif isinstance(mask_path_or_list, list):
                mask_paths = mask_path_or_list
            else:
                mask_paths = [mask_path_or_list]
            
            self.dynamic_file_info.append({
                'dynamic_path': str(dynamic_path),
                'time_offset': current_file_offset,
                'mask_paths': mask_paths,  # æ”¹ä¸ºåˆ—è¡¨ï¼Œæ”¯æŒå¤šä¸ªmaskæ–‡ä»¶
                'time_range': (file_min_time, file_max_time)  # è®°å½•æ—¶é—´æˆ³èŒƒå›´
            })
            
            # 4. ä¿å­˜maskè·¯å¾„ï¼ˆåŒæ—¶ä¿å­˜å¯¹åº”çš„æ—¶é—´åç§»é‡ä¿¡æ¯ï¼‰
            # ä¸ºäº†å‘åå…¼å®¹ï¼Œä»ç„¶ä¿å­˜åˆ°mask_data_pathsï¼ˆä½†åªä¿å­˜ç¬¬ä¸€ä¸ªï¼Œå¦‚æœæœ‰çš„è¯ï¼‰
            if mask_paths:
                self.mask_data_paths.append({
                    'path': mask_paths[0],  # å‘åå…¼å®¹ï¼šåªä¿å­˜ç¬¬ä¸€ä¸ª
                    'time_offset': current_file_offset
                })
        
        print(f"\nğŸ“Š åˆå¹¶åæ€»è®¡:")
        print(f"   é™æ€èŠ‚ç‚¹: {len(self.static_nodes)} ä¸ª")
        print(f"   åŠ¨æ€è®°å½•: {self.dynamic_df.shape[0]} æ¡")
        print(f"   æ—¶é—´æˆ³èŒƒå›´: {self.dynamic_df[self.time_col].min():.2f} ~ {self.dynamic_df[self.time_col].max():.2f}")
        
        # 4. éªŒè¯æ•°æ®ä¸€è‡´æ€§
        static_lane_ids = set(node[self.lane_id_col] for node in self.static_nodes)
        dynamic_lane_ids = set(self.dynamic_df[self.lane_id_col])
        
        if not dynamic_lane_ids.issubset(static_lane_ids):
            missing = dynamic_lane_ids - static_lane_ids
            print(f"âš ï¸ è­¦å‘Š: åŠ¨æ€æ•°æ®ä¸­æœ‰ {len(missing)} ä¸ª lane_id åœ¨é™æ€æ•°æ®ä¸­ä¸å­˜åœ¨")
        
        print(f"âœ… æ•°æ®ä¸€è‡´æ€§éªŒè¯é€šè¿‡")
        
    def _preprocess_data(self):
        """æ•°æ®é¢„å¤„ç†"""
        # æŒ‰æ—¶é—´å’Œlane_idæ’åº
        self.dynamic_df = self.dynamic_df.sort_values([self.time_col, self.lane_id_col])
        
        # ä»åŠ¨æ€æ•°æ®åˆ›å»ºå”¯ä¸€çš„æ—¶é—´æˆ³ç´¢å¼•
        self.timestamps = np.sort(self.dynamic_df[self.time_col].unique())
        # å¦‚æœæä¾›äº†maskæ–‡ä»¶ï¼Œå°†å…¶ä¸­çš„æ—¶é—´æˆ³å¹¶å…¥æ—¶é—´è½´ï¼Œç¡®ä¿maskä¸æ•°æ®æ—¶é—´å¯¹é½
        # ä»dynamic_file_infoä¸­è¯»å–æ‰€æœ‰maskæ–‡ä»¶
        has_mask_files = False
        for dyn_info in self.dynamic_file_info:
            mask_paths = dyn_info.get('mask_paths', [])
            if not mask_paths:
                mask_path = dyn_info.get('mask_path')
                if mask_path is not None:
                    mask_paths = [mask_path]
            if mask_paths:
                has_mask_files = True
                break
        
        if has_mask_files:
            mask_times = []
            for dyn_info in self.dynamic_file_info:
                mask_paths = dyn_info.get('mask_paths', [])
                if not mask_paths:
                    # å‘åå…¼å®¹
                    mask_path = dyn_info.get('mask_path')
                    if mask_path is not None:
                        mask_paths = [mask_path]
                
                time_offset = dyn_info.get('time_offset', 0.0)
                
                for mask_path in mask_paths:
                    if mask_path is None:
                        continue
                    mp = Path(mask_path)
                    if not mp.exists():
                        continue
                    try:
                        mask_df = pd.read_csv(mp)
                        if self.mask_time_col in mask_df.columns:
                            # åº”ç”¨ç›¸åŒçš„æ—¶é—´åç§»é‡
                            mask_times_adjusted = mask_df[self.mask_time_col].values + time_offset
                            mask_times.extend(mask_times_adjusted.tolist())
                    except Exception as e:
                        print(f"âš ï¸ è­¦å‘Š: è¯»å–æ©ç æ–‡ä»¶æ—¶é—´åˆ—å¤±è´¥ {mp}: {e}")
            if mask_times:
                union_times = np.unique(np.concatenate([self.timestamps, np.array(mask_times)]))
                if len(union_times) != len(self.timestamps):
                    added = len(union_times) - len(self.timestamps)
                    print(f"âœ… å·²å°†æ©ç æ–‡ä»¶ä¸­çš„ {added} ä¸ªæ—¶é—´æˆ³å¹¶å…¥æ—¶é—´è½´ï¼Œä¿è¯ä¸maskå¯¹é½")
                self.timestamps = union_times
        
        # è®°å½•æ¯ä¸ªæ–‡ä»¶å¯¹åº”çš„æ—¶é—´ç´¢å¼•èŒƒå›´ï¼ˆç”¨äºé¿å…çª—å£è·¨è¶Šæ–‡ä»¶è¾¹ç•Œï¼‰
        self.file_boundaries = []  # æ¯ä¸ªå…ƒç´ æ˜¯ (start_idx, end_idx) è¡¨ç¤ºæ–‡ä»¶åœ¨æ—¶é—´ç´¢å¼•ä¸­çš„èŒƒå›´
        time_to_idx = {t: idx for idx, t in enumerate(self.timestamps)}
        
        for i, dyn_info in enumerate(self.dynamic_file_info):
            dynamic_path = Path(dyn_info['dynamic_path'])
            
            # è·å–è¯¥æ–‡ä»¶çš„æ—¶é—´æˆ³èŒƒå›´ï¼ˆå·²åº”ç”¨åç§»é‡ï¼‰
            if 'time_range' in dyn_info:
                file_min_time, file_max_time = dyn_info['time_range']
            else:
                # å‘åå…¼å®¹ï¼šå¦‚æœæ²¡æœ‰ time_rangeï¼Œå°è¯•ä» dynamic_df ä¸­æ¨æ–­
                # è¿™éœ€è¦é‡æ–°è¯»å–æ–‡ä»¶ï¼Œæ•ˆç‡è¾ƒä½ï¼Œä½†å¯ä»¥å·¥ä½œ
                try:
                    df_original = pd.read_csv(dynamic_path)
                    time_offset = dyn_info['time_offset']
                    original_times = df_original[self.time_col].values
                    adjusted_times = original_times + time_offset
                    file_min_time = np.min(adjusted_times)
                    file_max_time = np.max(adjusted_times)
                except:
                    # å¦‚æœæ— æ³•è¯»å–ï¼Œè·³è¿‡è¿™ä¸ªæ–‡ä»¶
                    self.file_boundaries.append((0, 0))
                    continue
            
            # æ‰¾åˆ°è¯¥æ–‡ä»¶æ—¶é—´æˆ³èŒƒå›´å†…çš„æ‰€æœ‰æ—¶é—´ç´¢å¼•
            # æ³¨æ„ï¼šç”±äº mask æ–‡ä»¶å¯èƒ½æ·»åŠ äº†é¢å¤–æ—¶é—´æˆ³ï¼Œæˆ‘ä»¬éœ€è¦æ£€æŸ¥æ‰€æœ‰åœ¨èŒƒå›´å†…çš„ç´¢å¼•
            valid_indices = []
            for t_idx, timestamp in enumerate(self.timestamps):
                # æ£€æŸ¥æ—¶é—´æˆ³æ˜¯å¦åœ¨è¯¥æ–‡ä»¶çš„èŒƒå›´å†…ï¼ˆå…è®¸å°çš„æµ®ç‚¹è¯¯å·®ï¼‰
                if file_min_time - 1e-6 <= timestamp <= file_max_time + 1e-6:
                    valid_indices.append(t_idx)
            
            if valid_indices:
                start_idx = min(valid_indices)
                end_idx = max(valid_indices) + 1  # end_idx æ˜¯å¼€åŒºé—´
                self.file_boundaries.append((start_idx, end_idx))
                print(f"   æ–‡ä»¶ {i+1} ({dynamic_path.name}) æ—¶é—´ç´¢å¼•èŒƒå›´: [{start_idx}, {end_idx})")
            else:
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆç´¢å¼•ï¼Œä½¿ç”¨ç©ºèŒƒå›´
                self.file_boundaries.append((0, 0))
                print(f"   âš ï¸ è­¦å‘Š: æ–‡ä»¶ {i+1} ({dynamic_path.name}) æœªæ‰¾åˆ°æœ‰æ•ˆæ—¶é—´ç´¢å¼•")
        
        if len(self.file_boundaries) > 1:
            print(f"âœ… å·²è®°å½• {len(self.file_boundaries)} ä¸ªæ–‡ä»¶çš„è¾¹ç•Œä¿¡æ¯ï¼Œç”¨äºé˜²æ­¢çª—å£è·¨è¶Šæ–‡ä»¶è¾¹ç•Œ")
        
        # ä»é™æ€æ•°æ®åˆ›å»ºå”¯ä¸€çš„lane_idç´¢å¼•
        self.lane_ids = np.array([node[self.lane_id_col] for node in self.static_nodes])
        self.lane_ids = np.sort(np.unique(self.lane_ids))
        
        print(f"æ—¶é—´æ­¥æ•°: {len(self.timestamps)}")
        print(f"è½¦é“æ•°: {len(self.lane_ids)}")
        
        # æ£€æŸ¥å¹¶è¿‡æ»¤æœ‰æ•ˆçš„ç‰¹å¾åˆ—
        available_cols = [col for col in self.feature_cols if col in self.dynamic_df.columns]
        if len(available_cols) < len(self.feature_cols):
            missing_cols = set(self.feature_cols) - set(available_cols)
            print(f"âš ï¸ è­¦å‘Š: ä»¥ä¸‹ç‰¹å¾åˆ—ä¸å­˜åœ¨: {missing_cols}")
        self.feature_cols = available_cols
        print(f"ä½¿ç”¨ç‰¹å¾åˆ—: {self.feature_cols}")
        
        # æ„å»ºæ—¶ç©ºæ•°æ®çŸ©é˜µ
        self._build_spatiotemporal_matrix()
        
        # æ„å»ºå›¾è¿æ¥
        self._build_graph_connectivity()
        
        # åˆ›å»ºè®­ç»ƒ/è¯„ä¼°æ©ç 
        self._create_masks()
        
    def _build_spatiotemporal_matrix(self):
        """æ„å»ºæ—¶ç©ºæ•°æ®çŸ©é˜µ"""
        n_times = len(self.timestamps)
        n_lanes = len(self.lane_ids)
        n_features = len(self.feature_cols)
        
        # åˆå§‹åŒ–æ•°æ®çŸ©é˜µä¸ºNaN
        self.data = np.full((n_times, n_lanes, n_features), np.nan)
        
        # åˆ›å»ºlane_idåˆ°ç´¢å¼•çš„æ˜ å°„
        lane_id_to_idx = {lid: idx for idx, lid in enumerate(self.lane_ids)}
        time_to_idx = {t: idx for idx, t in enumerate(self.timestamps)}
        
        # å¡«å……æ•°æ®
        for _, row in self.dynamic_df.iterrows():
            time_idx = time_to_idx.get(row[self.time_col])
            lane_idx = lane_id_to_idx.get(row[self.lane_id_col])
            
            if time_idx is not None and lane_idx is not None:
                for f_idx, col in enumerate(self.feature_cols):
                    if col in row and pd.notna(row[col]):
                        # å¤„ç† -1.0 è¡¨ç¤ºä¸é€‚ç”¨çš„æƒ…å†µ
                        val = row[col]
                        if val == -1.0:
                            val = np.nan  # æˆ–è€…ä¿ç•™-1.0ï¼Œå–å†³äºä½ çš„éœ€æ±‚
                        self.data[time_idx, lane_idx, f_idx] = val
        
        # å¤„ç†ç¼ºå¤±å€¼
        nan_ratio = np.isnan(self.data).mean()
        print(f"åŸå§‹ç¼ºå¤±å€¼æ¯”ä¾‹: {nan_ratio:.3f}")

        # åœ¨å¡«å……ç¼ºå¤±å€¼å‰å…ˆåŸºäºåŸå§‹é€Ÿåº¦åºåˆ—æ„é€  DTSF æ‹¥å µçŠ¶æ€
        if self.enable_dtsf:
            self._append_dtsf_state()
        
        if self.impute_nans:
            # ä½¿ç”¨å‰å‘å¡«å……
            for i in range(1, n_times):
                mask = np.isnan(self.data[i])
                self.data[i][mask] = self.data[i-1][mask]
            # å‰©ä½™çš„NaNç”¨fill_valueå¡«å……
            self.data = np.nan_to_num(self.data, nan=self.fill_value)
                
        print(f"æ•°æ®çŸ©é˜µå½¢çŠ¶: {self.data.shape}")
        print(f"å¡«å……åç¼ºå¤±å€¼æ¯”ä¾‹: {np.isnan(self.data).mean():.3f}")

    def _append_dtsf_state(self):
        """åŸºäº avg_speed è®¡ç®—åŒæ—¶é—´å°ºåº¦æ‹¥å µéšçŠ¶æ€å¹¶è¿½åŠ ä¸ºæ–°ç‰¹å¾
        
        æ³¨æ„ï¼šå¦‚æœ avg_speed æ˜¯ç»å¯¹é€Ÿåº¦å€¼ï¼ˆkm/hï¼‰ï¼Œåœ¨è®¡ç®— DTSF åä¼šè‡ªåŠ¨å½’ä¸€åŒ–åˆ° 0-1 èŒƒå›´
        ä»¥ä¸å…¶ä»–å½’ä¸€åŒ–ç‰¹å¾ä¿æŒä¸€è‡´çš„å°ºåº¦
        """
        if 'avg_speed' not in self.feature_cols:
            print("âš ï¸ DTSF è·³è¿‡ï¼šæœªæ‰¾åˆ° avg_speed ç‰¹å¾åˆ—")
            return

        speed_idx = self.feature_cols.index('avg_speed')
        speed_matrix = self.data[..., speed_idx].copy()  # ä¿å­˜åŸå§‹é€Ÿåº¦å€¼ç”¨äº DTSF è®¡ç®—

        if np.isnan(speed_matrix).all():
            print("âš ï¸ DTSF è·³è¿‡ï¼šavg_speed å…¨ä¸ºç¼ºå¤±")
            return

        # æ£€æµ‹é€Ÿåº¦å€¼æ˜¯å¦å·²ç»æ˜¯å½’ä¸€åŒ–çš„ï¼ˆ0-1èŒƒå›´ï¼‰è¿˜æ˜¯ç»å¯¹é€Ÿåº¦å€¼ï¼ˆkm/hï¼‰
        finite_vals = speed_matrix[~np.isnan(speed_matrix)]
        if finite_vals.size > 0:
            speed_max = np.nanmax(speed_matrix)
            speed_min = np.nanmin(speed_matrix)
            is_normalized = speed_max <= 1.5  # å¦‚æœæœ€å¤§å€¼å°äºç­‰äº1.5ï¼Œè®¤ä¸ºæ˜¯å½’ä¸€åŒ–çš„
        else:
            is_normalized = True  # å¦‚æœå…¨ä¸ºNaNï¼Œé»˜è®¤è®¤ä¸ºæ˜¯å½’ä¸€åŒ–çš„
            speed_max = 1.0
            speed_min = 0.0

        # è‡ªåŠ¨è¯†åˆ«"æ— è½¦"æ ‡è®°å€¼ï¼ˆé’ˆå¯¹ 0~1 å½’ä¸€åŒ–ä¸”æ— è½¦=1 çš„åœºæ™¯ï¼‰
        no_car_value = self.dtsf_no_car_value
        if self.dtsf_auto_no_car and no_car_value is None:
            if is_normalized:
                no_car_value = 1.0

        z_state = np.zeros_like(speed_matrix, dtype=np.float32)
        n_times, n_lanes = speed_matrix.shape

        for lane_idx in range(n_lanes):
            lane_speed = speed_matrix[:, lane_idx]
            valid_vals = lane_speed[~np.isnan(lane_speed)]
            v_base_init = float(valid_vals[0]) if valid_vals.size > 0 else self.dtsf_v_base_init

            filter_module = DTStateFilter(
                gamma=self.dtsf_gamma,
                delta=self.dtsf_delta,
                vth_ratio=self.dtsf_vth_ratio,
                v_base_init=v_base_init,
                initial_z=self.dtsf_initial_z,
                device=self.dtsf_device,
            )

            with torch.no_grad():
                for t, v in enumerate(lane_speed):
                    v_obs = None
                    if not np.isnan(v):
                        is_no_car = False
                        if self.dtsf_treat_no_car_as_missing and no_car_value is not None:
                            is_no_car = v >= (no_car_value - self.dtsf_no_car_eps)
                        if not is_no_car:
                            v_obs = float(v)
                    z_val = filter_module(v_obs)
                    z_state[t, lane_idx] = float(z_val.detach().cpu())

        # æ·»åŠ  DTSF çŠ¶æ€ç‰¹å¾
        self.data = np.concatenate([self.data, z_state[..., None]], axis=-1)
        self.feature_cols.append('dtsf_congestion')
        
        # å¦‚æœ avg_speed æ˜¯ç»å¯¹é€Ÿåº¦å€¼ï¼ˆéå½’ä¸€åŒ–ï¼‰ï¼Œéœ€è¦å½’ä¸€åŒ–åˆ° 0-1 èŒƒå›´
        # ä»¥ä¸å…¶ä»–å½’ä¸€åŒ–ç‰¹å¾ä¿æŒä¸€è‡´çš„å°ºåº¦ï¼Œé¿å… StandardScaler æ ‡å‡†åŒ–æ—¶å°ºåº¦å·®å¼‚è¿‡å¤§
        if not is_normalized and finite_vals.size > 0:
            # ä½¿ç”¨ min-max å½’ä¸€åŒ–ï¼šå°†é€Ÿåº¦å€¼å½’ä¸€åŒ–åˆ° [0, 1] èŒƒå›´
            # ä½¿ç”¨å…¨å±€çš„æœ€å¤§æœ€å°å€¼ï¼Œç¡®ä¿æ‰€æœ‰è½¦é“ä½¿ç”¨ç›¸åŒçš„å½’ä¸€åŒ–å‚æ•°
            speed_range = speed_max - speed_min
            if speed_range > 1e-6:  # é¿å…é™¤é›¶
                normalized_speed = (speed_matrix - speed_min) / speed_range
                # æ›´æ–°æ•°æ®çŸ©é˜µä¸­çš„ avg_speed å€¼
                self.data[..., speed_idx] = normalized_speed
                # ä¿å­˜å½’ä¸€åŒ–å‚æ•°ï¼Œç”¨äºæ¨ç†æ—¶åå½’ä¸€åŒ–
                self.speed_normalization_params = {
                    'speed_min': float(speed_min),
                    'speed_max': float(speed_max),
                    'is_normalized': False,
                    'feature_idx': speed_idx
                }
                print(f"âœ… å·²å°† avg_speed ä»ç»å¯¹é€Ÿåº¦å€¼ ({speed_min:.2f}-{speed_max:.2f} km/h) å½’ä¸€åŒ–åˆ° [0, 1] èŒƒå›´")
                print(f"   å·²ä¿å­˜å½’ä¸€åŒ–å‚æ•°: min={speed_min:.2f}, max={speed_max:.2f} km/h")
            else:
                print(f"âš ï¸ avg_speed å€¼èŒƒå›´è¿‡å° ({speed_min:.2f}-{speed_max:.2f})ï¼Œè·³è¿‡å½’ä¸€åŒ–")
        else:
            # å¦‚æœå·²ç»æ˜¯å½’ä¸€åŒ–çš„ï¼Œä¹Ÿä¿å­˜å‚æ•°ï¼ˆè™½ç„¶ä¸éœ€è¦åå½’ä¸€åŒ–ï¼‰
            self.speed_normalization_params = {
                'speed_min': 0.0,
                'speed_max': 1.0,
                'is_normalized': True,
                'feature_idx': speed_idx
            }
        
        print("âœ… å·²æ·»åŠ  DTSF æ‹¥å µçŠ¶æ€ç‰¹å¾ï¼Œå½“å‰ç‰¹å¾æ•°:", len(self.feature_cols))
        
    def _build_graph_connectivity(self):
        """æ„å»ºåŸºäºèŠ‚ç‚¹è¿æ¥è§„åˆ™çš„å›¾è¿æ¥"""
        n_lanes = len(self.lane_ids)
        adj_matrix = np.zeros((n_lanes, n_lanes))
        
        # åˆ›å»ºlane_idåˆ°ç´¢å¼•çš„æ˜ å°„
        lane_id_to_idx = {lid: idx for idx, lid in enumerate(self.lane_ids)}
        
        # éå†é™æ€èŠ‚ç‚¹ï¼Œæ„å»ºé‚»æ¥çŸ©é˜µ
        for node in self.static_nodes:
            source_lane = node[self.lane_id_col]
            if source_lane not in lane_id_to_idx:
                continue
            source_idx = lane_id_to_idx[source_lane]
            
            # è·å–èŠ‚ç‚¹è¿æ¥ä¿¡æ¯
            connections = node.get('node_connections', {})
            if isinstance(connections, str):
                try:
                    connections = json.loads(connections)
                except:
                    connections = {}
            
            # å¤„ç†ä¸åŒç±»å‹çš„è¿æ¥
            for conn_type, targets in connections.items():
                if not isinstance(targets, list):
                    targets = [targets]
                
                for target_lane in targets:
                    if target_lane in lane_id_to_idx:
                        target_idx = lane_id_to_idx[target_lane]
                        
                        # æ ¹æ®è¿æ¥ç±»å‹è®¾ç½®æƒé‡
                        if conn_type == 'direct':
                            weight = 1.0
                        elif conn_type == 'near':
                            weight = 0.5
                        elif conn_type == 'crossing':
                            weight = 0.5
                        else:
                            weight = 0.5
                        
                        # æ·»åŠ åŒå‘è¿æ¥
                        adj_matrix[source_idx, target_idx] = max(adj_matrix[source_idx, target_idx], weight)
                        adj_matrix[target_idx, source_idx] = max(adj_matrix[target_idx, source_idx], weight)
        
        self.adjacency = adj_matrix
        print(f"å›¾è¿æ¥çŸ©é˜µå½¢çŠ¶: {self.adjacency.shape}")
        print(f"è¿æ¥æ•°: {np.sum(adj_matrix > 0) // 2}")
        
    def _create_masks(self):
        """åˆ›å»ºè®­ç»ƒ/è¯„ä¼°æ©ç ï¼ˆæ”¯æŒå¤šç»„maskæ–‡ä»¶ï¼Œæ¯ä¸ªmaskå¯ä»¥æ˜¯åˆ—è¡¨ï¼‰"""
        n_times, n_lanes, n_features = self.data.shape
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ä»»ä½•maskæ–‡ä»¶ï¼ˆä»dynamic_file_infoä¸­æ£€æŸ¥ï¼‰
        has_masks = False
        for dyn_info in self.dynamic_file_info:
            mask_paths = dyn_info.get('mask_paths', [])
            if not mask_paths:
                # å‘åå…¼å®¹
                mask_path = dyn_info.get('mask_path')
                if mask_path is not None:
                    mask_paths = [mask_path]
            if mask_paths:
                has_masks = True
                break
        
        if has_masks:
            self._load_user_masks()
            print(f"âœ… ä½¿ç”¨ç”¨æˆ·è‡ªå®šä¹‰æ©ç ")
            print(f"   å·²è§‚æµ‹æ•°æ®æ¯”ä¾‹: {self.training_mask.mean():.3f}")
            print(f"   æœªè§‚æµ‹æ•°æ®æ¯”ä¾‹: {self.eval_mask.mean():.3f}")
        else:
            # é»˜è®¤ï¼šæ‰€æœ‰æ•°æ®ç”¨äºè®­ç»ƒï¼Œéšæœºé€‰æ‹©20%ç”¨äºè¯„ä¼°
            self.training_mask = np.ones((n_times, n_lanes, n_features), dtype=bool)
            
            np.random.seed(42)
            eval_indices = np.random.choice(
                n_times * n_lanes * n_features,
                size=int(0.2 * n_times * n_lanes * n_features),
                replace=False
            )
            
            self.eval_mask = np.zeros((n_times, n_lanes, n_features), dtype=bool)
            eval_mask_flat = self.eval_mask.reshape(-1)
            eval_mask_flat[eval_indices] = True
            print(f"âœ… ä½¿ç”¨éšæœºç”Ÿæˆçš„æ©ç ")
            
    def _load_user_masks(self):
        """ä»ç”¨æˆ·æä¾›çš„å¤šä¸ªCSVæ–‡ä»¶åŠ è½½æ©ç æ•°æ®ï¼ˆæ”¯æŒæ¯ä¸ªdynamicæ–‡ä»¶å¯¹åº”å¤šä¸ªmaskæ–‡ä»¶ï¼‰"""
        n_times, n_lanes, n_features = self.data.shape
        
        # åˆå§‹åŒ–æ©ç çŸ©é˜µï¼ˆé»˜è®¤æ‰€æœ‰ä½ç½®éƒ½æ˜¯æœªè§‚æµ‹çš„ï¼‰
        self.training_mask = np.zeros((n_times, n_lanes, n_features), dtype=bool)
        
        # åˆ›å»ºç´¢å¼•æ˜ å°„
        lane_id_to_idx = {lid: idx for idx, lid in enumerate(self.lane_ids)}
        time_to_idx = {t: idx for idx, t in enumerate(self.timestamps)}
        
        # ä»dynamic_file_infoä¸­åŠ è½½æ‰€æœ‰maskæ–‡ä»¶
        file_idx = 0
        for dyn_info in self.dynamic_file_info:
            mask_paths = dyn_info.get('mask_paths', [])
            if not mask_paths:
                # å‘åå…¼å®¹ï¼šå¦‚æœæ²¡æœ‰mask_pathsï¼Œå°è¯•ä½¿ç”¨mask_path
                mask_path = dyn_info.get('mask_path')
                if mask_path is not None:
                    mask_paths = [mask_path]
            
            time_offset = dyn_info.get('time_offset', 0.0)
            
            # åŠ è½½è¯¥dynamicæ–‡ä»¶å¯¹åº”çš„æ‰€æœ‰maskæ–‡ä»¶
            for mask_path in mask_paths:
                if mask_path is None:
                    continue
                
                file_idx += 1
                mask_path_obj = Path(mask_path)
                if not mask_path_obj.exists():
                    print(f"âš ï¸ è­¦å‘Š: æ©ç æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡: {mask_path_obj}")
                    continue
                
                print(f"   åŠ è½½æ©ç æ–‡ä»¶ {file_idx}: {mask_path_obj.name} (æ—¶é—´åç§»é‡: {time_offset:.2f})")
                try:
                    mask_df = pd.read_csv(mask_path_obj)
                    
                    # æ£€æŸ¥å¿…éœ€åˆ—
                    required_cols = [self.mask_time_col, self.mask_lane_col, self.mask_value_col]
                    missing_cols = [col for col in required_cols if col not in mask_df.columns]
                    if missing_cols:
                        raise ValueError(f"æ©ç æ–‡ä»¶ {mask_path_obj} ç¼ºå°‘å¿…éœ€åˆ—: {missing_cols}")
                    
                    # åº”ç”¨æ—¶é—´åç§»é‡åˆ°maskæ–‡ä»¶çš„æ—¶é—´æˆ³
                    mask_df = mask_df.copy()
                    mask_df[self.mask_time_col] = mask_df[self.mask_time_col] + time_offset
                    
                    # å¡«å……æ©ç 
                    for _, row in mask_df.iterrows():
                        time_val = row[self.mask_time_col]
                        lane_id = row[self.mask_lane_col]
                        is_observed = bool(row[self.mask_value_col])
                        
                        time_idx = time_to_idx.get(time_val)
                        lane_idx = lane_id_to_idx.get(lane_id)
                        
                        if time_idx is not None and lane_idx is not None:
                            # å¯¹æ‰€æœ‰ç‰¹å¾éƒ½ä½¿ç”¨ç›¸åŒçš„æ©ç 
                            self.training_mask[time_idx, lane_idx, :] = is_observed
                        elif time_idx is None:
                            # æ—¶é—´æˆ³ä¸åœ¨æ—¶é—´è½´ä¸­ï¼Œå¯èƒ½æ˜¯maskæ–‡ä»¶çš„æ—¶é—´æˆ³èŒƒå›´è¶…å‡ºäº†æ•°æ®èŒƒå›´
                            pass  # é™é»˜å¿½ç•¥ï¼Œå› ä¸ºæ—¶é—´æˆ³å¯èƒ½å·²ç»åœ¨åˆå¹¶æ—¶å¤„ç†è¿‡äº†
                except Exception as e:
                    print(f"âš ï¸ è­¦å‘Š: åŠ è½½æ©ç æ–‡ä»¶å¤±è´¥ {mask_path_obj}: {e}")
                    continue
        
        # è¯„ä¼°æ©ç æ˜¯è®­ç»ƒæ©ç çš„å
        self.eval_mask = ~self.training_mask
    
    def _initialize_mask_files(self):
        """
        ä»data_groupsä¸­è‡ªåŠ¨æå–æ‰€æœ‰maskæ–‡ä»¶
        æ”¯æŒæ¯ä¸ªdynamicæ–‡ä»¶å¯¹åº”å¤šä¸ªmaskæ–‡ä»¶ï¼ˆmaskå­—æ®µå¯ä»¥æ˜¯åˆ—è¡¨ï¼‰
        """
        print(f"\nğŸ“‹ ä»data_groupsä¸­è‡ªåŠ¨æå–maskæ–‡ä»¶...")
        for dyn_info in self.dynamic_file_info:
            mask_paths = dyn_info.get('mask_paths', [])
            if not mask_paths:
                # å‘åå…¼å®¹ï¼šå¦‚æœæ²¡æœ‰mask_pathsï¼Œå°è¯•ä½¿ç”¨mask_path
                mask_path = dyn_info.get('mask_path')
                if mask_path is not None:
                    mask_paths = [mask_path]
            
            # æ”¯æŒæ¯ä¸ªdynamicæ–‡ä»¶å¯¹åº”å¤šä¸ªmaskæ–‡ä»¶
            for mask_path in mask_paths:
                if mask_path is None:
                    continue
                mask_path_obj = Path(mask_path)
                if mask_path_obj.exists():
                    self.mask_files.append({
                        'path': str(mask_path_obj),
                        'time_offset': dyn_info['time_offset'],
                        'dynamic_path': dyn_info['dynamic_path']
                    })
                    print(f"   âœ… {mask_path_obj.name} -> {Path(dyn_info['dynamic_path']).name} (æ—¶é—´åç§»: {dyn_info['time_offset']:.2f})")
                else:
                    print(f"   âš ï¸  maskæ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡: {mask_path_obj}")
        
        if len(self.mask_files) == 0:
            print(f"âš ï¸  è­¦å‘Š: æ²¡æœ‰å¯ç”¨çš„maskæ–‡ä»¶ç”¨äºåŠ¨æ€åˆ‡æ¢")
        else:
            print(f"âœ… å…±æ‰¾åˆ° {len(self.mask_files)} ä¸ªmaskæ–‡ä»¶å¯ç”¨äºåŠ¨æ€åˆ‡æ¢")
    
    def switch_mask_sequentially(self, epoch: Optional[int] = None) -> bool:
        """
        ä»mask_filesåˆ—è¡¨ä¸­æŒ‰é¡ºåºå¾ªç¯é€‰æ‹©ä¸€ä¸ªmaskæ–‡ä»¶å¹¶åŠ è½½ï¼Œç”¨äºè®­ç»ƒæ—¶åŠ¨æ€åˆ‡æ¢mask
        è‡ªåŠ¨åº”ç”¨å¯¹åº”dynamicæ–‡ä»¶çš„æ—¶é—´åç§»é‡
        
        Args:
            epoch: å½“å‰epochç¼–å·ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨å†…éƒ¨ç´¢å¼•è‡ªåŠ¨é€’å¢
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸåˆ‡æ¢mask
        """
        if not self.mask_files:
            return False
        
        # å¦‚æœæä¾›äº†epochç¼–å·ï¼Œä½¿ç”¨å®ƒæ¥é€‰æ‹©maskæ–‡ä»¶ï¼ˆå¾ªç¯ï¼‰
        if epoch is not None:
            mask_index = epoch % len(self.mask_files)
        else:
            # å¦åˆ™ä½¿ç”¨å†…éƒ¨ç´¢å¼•ï¼Œå¹¶åœ¨æ¯æ¬¡è°ƒç”¨åé€’å¢
            mask_index = self.current_mask_index
            self.current_mask_index = (self.current_mask_index + 1) % len(self.mask_files)
        
        # æŒ‰é¡ºåºé€‰æ‹©ä¸€ä¸ªmaskæ–‡ä»¶ï¼ˆåŒ…å«åŒ¹é…ä¿¡æ¯ï¼‰
        selected_mask_info = self.mask_files[mask_index]
        selected_mask_file = selected_mask_info['path']
        time_offset = selected_mask_info['time_offset']
        dynamic_path = selected_mask_info['dynamic_path']
        
        self.current_mask_file = selected_mask_file
        
        print(f"ğŸ”„ åˆ‡æ¢åˆ°maskæ–‡ä»¶ ({mask_index + 1}/{len(self.mask_files)}): {Path(selected_mask_file).name}")
        print(f"   å¯¹åº”dynamicæ–‡ä»¶: {Path(dynamic_path).name}")
        print(f"   æ—¶é—´åç§»é‡: {time_offset:.2f}")
        
        # åŠ è½½é€‰ä¸­çš„maskæ–‡ä»¶
        n_times, n_lanes, n_features = self.data.shape
        
        # åˆå§‹åŒ–æ©ç çŸ©é˜µï¼ˆé»˜è®¤æ‰€æœ‰ä½ç½®éƒ½æ˜¯æœªè§‚æµ‹çš„ï¼‰
        new_training_mask = np.zeros((n_times, n_lanes, n_features), dtype=bool)
        
        # åˆ›å»ºç´¢å¼•æ˜ å°„
        lane_id_to_idx = {lid: idx for idx, lid in enumerate(self.lane_ids)}
        time_to_idx = {t: idx for idx, t in enumerate(self.timestamps)}
        
        # åŠ è½½maskæ–‡ä»¶
        mask_path = Path(selected_mask_file)
        if not mask_path.exists():
            print(f"âš ï¸ è­¦å‘Š: æ©ç æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡: {mask_path}")
            return False
        
        try:
            mask_df = pd.read_csv(mask_path)
            
            # æ£€æŸ¥å¿…éœ€åˆ—
            required_cols = [self.mask_time_col, self.mask_lane_col, self.mask_value_col]
            missing_cols = [col for col in required_cols if col not in mask_df.columns]
            if missing_cols:
                print(f"âš ï¸ è­¦å‘Š: æ©ç æ–‡ä»¶ {mask_path} ç¼ºå°‘å¿…éœ€åˆ—: {missing_cols}")
                return False
            
            # åº”ç”¨æ—¶é—´åç§»é‡åˆ°maskæ–‡ä»¶çš„æ—¶é—´æˆ³ï¼ˆç¡®ä¿ä¸å¯¹åº”çš„dynamicæ–‡ä»¶å¯¹é½ï¼‰
            mask_df = mask_df.copy()
            mask_df[self.mask_time_col] = mask_df[self.mask_time_col] + time_offset
            
            # å¡«å……æ©ç 
            for _, row in mask_df.iterrows():
                time_val = row[self.mask_time_col]
                lane_id = row[self.mask_lane_col]
                is_observed = bool(row[self.mask_value_col])
                
                time_idx = time_to_idx.get(time_val)
                lane_idx = lane_id_to_idx.get(lane_id)
                
                if time_idx is not None and lane_idx is not None:
                    # å¯¹æ‰€æœ‰ç‰¹å¾éƒ½ä½¿ç”¨ç›¸åŒçš„æ©ç 
                    new_training_mask[time_idx, lane_idx, :] = is_observed
            
            # æ›´æ–°mask
            self.training_mask = new_training_mask
            self.eval_mask = ~self.training_mask
            
            print(f"âœ… å·²æ›´æ–°maskï¼Œå·²è§‚æµ‹æ•°æ®æ¯”ä¾‹: {self.training_mask.mean():.3f}")
            return True
            
        except Exception as e:
            print(f"âš ï¸ è­¦å‘Š: åŠ è½½æ©ç æ–‡ä»¶å¤±è´¥: {e}")
            return False
        
    def get_connectivity(self, threshold: float = 0.1, 
                        include_self: bool = False,
                        force_symmetric: bool = True) -> np.ndarray:
        """è·å–å›¾è¿æ¥çŸ©é˜µ"""
        adj = self.adjacency.copy()
        
        # åº”ç”¨é˜ˆå€¼ï¼Œè½¬ä¸ºäºŒå€¼çŸ©é˜µ
        adj = (adj >= threshold).astype(np.uint8)
        
        if not include_self:
            np.fill_diagonal(adj, 0)
            
        if force_symmetric:
            adj = np.maximum(adj, adj.T)
            
        return adj
        
    def numpy(self, return_idx: bool = False) -> Union[Tuple, np.ndarray]:
        """è¿”å›numpyæ ¼å¼çš„æ•°æ®"""
        if return_idx:
            return self.data, self.timestamps, self.lane_ids
        return self.data
        
    def datetime_encoded(self, encoding: List[str]) -> pd.DataFrame:
        """
        è·å–æ—¶é—´ç¼–ç  - ä½¿ç”¨çœŸå®æ—¶é—´å·®ï¼ˆä¸åš sin/cosï¼‰ï¼Œå¹¶ä¿ç•™ç›¸å¯¹è¿›åº¦

        è¿”å›ä¸¤åˆ—ï¼š
        - time_linear: ç›¸å¯¹è¿›åº¦ [0,1]
        - delta_t: ç›¸é‚»æ—¶é—´æ­¥çš„çœŸå®æ—¶é—´å·®ï¼ˆä¸åŸå§‹æ—¶é—´æˆ³åŒå•ä½ï¼‰ï¼Œé¦–ä¸ªæ—¶é—´æ­¥ç½® 0
        """
        n_times = len(self.timestamps)
        df = pd.DataFrame(index=range(n_times))

        # å½’ä¸€åŒ–æ—¶é—´ä½ç½® [0, 1]
        t_min, t_max = self.timestamps.min(), self.timestamps.max()
        normalized_t = (self.timestamps - t_min) / (t_max - t_min + 1e-8)
        df['time_linear'] = normalized_t

        # çœŸå®æ—¶é—´å·®ç‰¹å¾ï¼ˆé¦–æ­¥ä¸º 0ï¼‰
        ts = self.timestamps.astype(float)
        delta = np.diff(ts, prepend=ts[0])
        df['delta_t'] = delta

        return df
        
    def get_splitter(self, val_len: float = None, test_len: float = None):
        """è·å–æ•°æ®åˆ†å‰²å™¨"""
        from tsl.data.datamodule.splitters import TemporalSplitter
        
        val_len = val_len or self.val_len
        test_len = test_len or self.test_len
        
        return TemporalSplitter(val_len=val_len, test_len=test_len)
        
    @property
    def n_nodes(self) -> int:
        """èŠ‚ç‚¹æ•°é‡"""
        return len(self.lane_ids)
        
    @property
    def n_channels(self) -> int:
        """ç‰¹å¾é€šé“æ•°"""
        return self.data.shape[-1]
        
    @property
    def length(self) -> int:
        """æ—¶é—´åºåˆ—é•¿åº¦"""
        return len(self.timestamps)
        
    def __len__(self) -> int:
        return self.length
        
    def __getitem__(self, idx: int) -> Dict[str, Any]:
        """è·å–å•ä¸ªæ—¶é—´æ­¥çš„æ•°æ®"""
        return {
            'data': self.data[idx],
            'timestamp': self.timestamps[idx],
            'lane_ids': self.lane_ids
        }
