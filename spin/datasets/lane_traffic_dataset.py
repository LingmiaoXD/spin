"""
è½¦é“çº§äº¤é€šçŠ¶å†µæ•°æ®é›†ç±»
æ”¯æŒé™æ€é“è·¯æ•°æ®(graph.json)å’ŒåŠ¨æ€äº¤é€šæ•°æ®(csv)ï¼Œä»¥åŠç”¨æˆ·è‡ªå®šä¹‰æ©ç 
"""

import numpy as np
import pandas as pd
import torch
from typing import Optional, Tuple, Union, List, Dict, Any
from pathlib import Path
import pickle
import json
from tsl.datasets import Dataset
from tsl.data import SpatioTemporalDataset
from tsl.data.preprocessing import StandardScaler
from tsl.ops.connectivity import adj_to_edge_index
from tsl.utils.python_utils import ensure_list


class LaneTrafficDataset(Dataset):
    """
    è½¦é“çº§äº¤é€šçŠ¶å†µæ•°æ®é›†
    
    æ•°æ®æ ¼å¼ï¼š
    - é™æ€æ•°æ®(graph.json): åŒ…å« lane_id å’Œ node_connections
    - åŠ¨æ€æ•°æ®(csv): åŒ…å« lane_id, start_frame, avg_speed, avg_occupancy ç­‰ç‰¹å¾
    - æ©ç æ•°æ®(csv): åŒ…å« start_frame, lane_id, is_observed
    
    æ”¯æŒä¸¤ç§è¾“å…¥æ–¹å¼ï¼š
    1. å•ç»„æ•°æ®ï¼šç›´æ¥ä¼ å…¥ static_data_path, dynamic_data_path, mask_data_path
    2. å¤šç»„æ•°æ®ï¼šä¼ å…¥ data_groups åˆ—è¡¨ï¼Œæ¯ç»„åŒ…å« static, dynamic, mask è·¯å¾„
    """
    
    # é»˜è®¤ç‰¹å¾åˆ—ï¼ˆå¯é…ç½®ï¼‰
    DEFAULT_FEATURE_COLS = [
        'avg_speed', 'avg_occupancy', 'total_vehicles', 
        'car_ratio', 'medium_ratio', 'heavy_ratio', 'motorcycle_ratio'
    ]
    
    def __init__(self, 
                 static_data_path: Optional[str] = None,
                 dynamic_data_path: Optional[str] = None,
                 mask_data_path: Optional[str] = None,
                 data_groups: Optional[List[Dict[str, str]]] = None,
                 feature_cols: Optional[List[str]] = None,
                 time_col: str = 'start_frame',
                 lane_id_col: str = 'lane_id',
                 mask_time_col: str = 'start_frame',
                 mask_lane_col: str = 'lane_id',
                 mask_value_col: str = 'is_observed',
                 window_size: int = 10,
                 stride: int = 1,
                 val_len: float = 0.1,
                 test_len: float = 0.2,
                 impute_nans: bool = True,
                 fill_value: float = 0.0,
                 **kwargs):
        """
        åˆå§‹åŒ–è½¦é“çº§äº¤é€šæ•°æ®é›†
        
        Args:
            static_data_path: é™æ€é“è·¯æ•°æ®æ–‡ä»¶è·¯å¾„(graph.json)ï¼Œå•ç»„æ•°æ®æ—¶ä½¿ç”¨
            dynamic_data_path: åŠ¨æ€äº¤é€šæ•°æ®æ–‡ä»¶è·¯å¾„(csv)ï¼Œå•ç»„æ•°æ®æ—¶ä½¿ç”¨
            mask_data_path: ç”¨æˆ·è‡ªå®šä¹‰æ©ç æ–‡ä»¶è·¯å¾„(csv)ï¼Œå¯é€‰
            data_groups: å¤šç»„æ•°æ®é…ç½®åˆ—è¡¨ï¼Œæ¯ç»„æ ¼å¼ä¸º:
                         [{"static": "path1.json", "dynamic": "path1.csv", "mask": "mask1.csv"}, ...]
            feature_cols: è¦ä½¿ç”¨çš„ç‰¹å¾åˆ—ååˆ—è¡¨ï¼Œé»˜è®¤ä½¿ç”¨æ‰€æœ‰æ•°å€¼ç‰¹å¾
            time_col: åŠ¨æ€æ•°æ®ä¸­çš„æ—¶é—´åˆ—å
            lane_id_col: è½¦é“IDåˆ—å
            mask_time_col: æ©ç æ–‡ä»¶ä¸­çš„æ—¶é—´åˆ—å
            mask_lane_col: æ©ç æ–‡ä»¶ä¸­çš„è½¦é“IDåˆ—å
            mask_value_col: æ©ç æ–‡ä»¶ä¸­çš„è§‚æµ‹å€¼åˆ—å
            window_size: æ—¶é—´çª—å£å¤§å°
            stride: æ—¶é—´æ­¥é•¿
            val_len: éªŒè¯é›†æ¯”ä¾‹
            test_len: æµ‹è¯•é›†æ¯”ä¾‹
            impute_nans: æ˜¯å¦å¡«å……ç¼ºå¤±å€¼
            fill_value: ç¼ºå¤±å€¼å¡«å……å€¼
        """
        super().__init__(**kwargs)
        
        # å¤„ç†æ•°æ®è·¯å¾„ï¼šæ”¯æŒå•ç»„æˆ–å¤šç»„
        if data_groups is not None:
            self.data_groups = data_groups
        elif static_data_path is not None and dynamic_data_path is not None:
            self.data_groups = [{
                'static': static_data_path,
                'dynamic': dynamic_data_path,
                'mask': mask_data_path
            }]
        else:
            raise ValueError("å¿…é¡»æä¾› data_groups æˆ– (static_data_path + dynamic_data_path)")
        
        self.feature_cols = feature_cols or self.DEFAULT_FEATURE_COLS
        self.time_col = time_col
        self.lane_id_col = lane_id_col
        self.mask_time_col = mask_time_col
        self.mask_lane_col = mask_lane_col
        self.mask_value_col = mask_value_col
        self.window_size = window_size
        self.stride = stride
        self.val_len = val_len
        self.test_len = test_len
        self.impute_nans = impute_nans
        self.fill_value = fill_value
        
        # åŠ è½½å’Œé¢„å¤„ç†æ•°æ®
        self._load_data()
        self._preprocess_data()
        
    def _load_data(self):
        """åŠ è½½é™æ€é“è·¯æ•°æ®å’ŒåŠ¨æ€äº¤é€šæ•°æ®ï¼ˆæ”¯æŒå¤šç»„ï¼‰"""
        self.static_nodes = []
        self.dynamic_df = pd.DataFrame()
        self.mask_data_paths = []  # ä¿å­˜æ‰€æœ‰maskè·¯å¾„ä¾›åç»­ä½¿ç”¨
        
        for i, group in enumerate(self.data_groups):
            print(f"\nğŸ“‚ åŠ è½½ç¬¬ {i+1}/{len(self.data_groups)} ç»„æ•°æ®...")
            
            # 1. åŠ è½½é™æ€é“è·¯æ•°æ® (graph.json)
            static_path = Path(group['static'])
            if static_path.suffix == '.json':
                with open(static_path, 'r', encoding='utf-8') as f:
                    static_data = json.load(f)
                if 'nodes' in static_data:
                    nodes = static_data['nodes']
                else:
                    nodes = static_data
                self.static_nodes.extend(nodes)
                print(f"   âœ… é™æ€æ•°æ®: {len(nodes)} ä¸ªèŠ‚ç‚¹")
            else:
                raise ValueError(f"é™æ€æ•°æ®æ–‡ä»¶åº”ä¸ºJSONæ ¼å¼: {static_path.suffix}")
            
            # 2. åŠ è½½åŠ¨æ€äº¤é€šæ•°æ® (csv)
            dynamic_path = Path(group['dynamic'])
            if dynamic_path.suffix == '.csv':
                df = pd.read_csv(dynamic_path)
                self.dynamic_df = pd.concat([self.dynamic_df, df], ignore_index=True)
                print(f"   âœ… åŠ¨æ€æ•°æ®: {df.shape[0]} æ¡è®°å½•")
            else:
                raise ValueError(f"åŠ¨æ€æ•°æ®æ–‡ä»¶åº”ä¸ºCSVæ ¼å¼: {dynamic_path.suffix}")
            
            # 3. ä¿å­˜maskè·¯å¾„
            mask_path = group.get('mask')
            self.mask_data_paths.append(mask_path)
        
        print(f"\nğŸ“Š åˆå¹¶åæ€»è®¡:")
        print(f"   é™æ€èŠ‚ç‚¹: {len(self.static_nodes)} ä¸ª")
        print(f"   åŠ¨æ€è®°å½•: {self.dynamic_df.shape[0]} æ¡")
        
        # 4. éªŒè¯æ•°æ®ä¸€è‡´æ€§
        static_lane_ids = set(node[self.lane_id_col] for node in self.static_nodes)
        dynamic_lane_ids = set(self.dynamic_df[self.lane_id_col])
        
        if not dynamic_lane_ids.issubset(static_lane_ids):
            missing = dynamic_lane_ids - static_lane_ids
            print(f"âš ï¸ è­¦å‘Š: åŠ¨æ€æ•°æ®ä¸­æœ‰ {len(missing)} ä¸ª lane_id åœ¨é™æ€æ•°æ®ä¸­ä¸å­˜åœ¨")
        
        print(f"âœ… æ•°æ®ä¸€è‡´æ€§éªŒè¯é€šè¿‡")
        
    def _preprocess_data(self):
        """æ•°æ®é¢„å¤„ç†"""
        # æŒ‰æ—¶é—´å’Œlane_idæ’åº
        self.dynamic_df = self.dynamic_df.sort_values([self.time_col, self.lane_id_col])
        
        # ä»åŠ¨æ€æ•°æ®åˆ›å»ºå”¯ä¸€çš„æ—¶é—´æˆ³ç´¢å¼•
        self.timestamps = np.sort(self.dynamic_df[self.time_col].unique())
        
        # ä»é™æ€æ•°æ®åˆ›å»ºå”¯ä¸€çš„lane_idç´¢å¼•
        self.lane_ids = np.array([node[self.lane_id_col] for node in self.static_nodes])
        self.lane_ids = np.sort(np.unique(self.lane_ids))
        
        print(f"æ—¶é—´æ­¥æ•°: {len(self.timestamps)}")
        print(f"è½¦é“æ•°: {len(self.lane_ids)}")
        
        # æ£€æŸ¥å¹¶è¿‡æ»¤æœ‰æ•ˆçš„ç‰¹å¾åˆ—
        available_cols = [col for col in self.feature_cols if col in self.dynamic_df.columns]
        if len(available_cols) < len(self.feature_cols):
            missing_cols = set(self.feature_cols) - set(available_cols)
            print(f"âš ï¸ è­¦å‘Š: ä»¥ä¸‹ç‰¹å¾åˆ—ä¸å­˜åœ¨: {missing_cols}")
        self.feature_cols = available_cols
        print(f"ä½¿ç”¨ç‰¹å¾åˆ—: {self.feature_cols}")
        
        # æ„å»ºæ—¶ç©ºæ•°æ®çŸ©é˜µ
        self._build_spatiotemporal_matrix()
        
        # æ„å»ºå›¾è¿æ¥
        self._build_graph_connectivity()
        
        # åˆ›å»ºè®­ç»ƒ/è¯„ä¼°æ©ç 
        self._create_masks()
        
    def _build_spatiotemporal_matrix(self):
        """æ„å»ºæ—¶ç©ºæ•°æ®çŸ©é˜µ"""
        n_times = len(self.timestamps)
        n_lanes = len(self.lane_ids)
        n_features = len(self.feature_cols)
        
        # åˆå§‹åŒ–æ•°æ®çŸ©é˜µä¸ºNaN
        self.data = np.full((n_times, n_lanes, n_features), np.nan)
        
        # åˆ›å»ºlane_idåˆ°ç´¢å¼•çš„æ˜ å°„
        lane_id_to_idx = {lid: idx for idx, lid in enumerate(self.lane_ids)}
        time_to_idx = {t: idx for idx, t in enumerate(self.timestamps)}
        
        # å¡«å……æ•°æ®
        for _, row in self.dynamic_df.iterrows():
            time_idx = time_to_idx.get(row[self.time_col])
            lane_idx = lane_id_to_idx.get(row[self.lane_id_col])
            
            if time_idx is not None and lane_idx is not None:
                for f_idx, col in enumerate(self.feature_cols):
                    if col in row and pd.notna(row[col]):
                        # å¤„ç† -1.0 è¡¨ç¤ºä¸é€‚ç”¨çš„æƒ…å†µ
                        val = row[col]
                        if val == -1.0:
                            val = np.nan  # æˆ–è€…ä¿ç•™-1.0ï¼Œå–å†³äºä½ çš„éœ€æ±‚
                        self.data[time_idx, lane_idx, f_idx] = val
        
        # å¤„ç†ç¼ºå¤±å€¼
        nan_ratio = np.isnan(self.data).mean()
        print(f"åŸå§‹ç¼ºå¤±å€¼æ¯”ä¾‹: {nan_ratio:.3f}")
        
        if self.impute_nans:
            # ä½¿ç”¨å‰å‘å¡«å……
            for i in range(1, n_times):
                mask = np.isnan(self.data[i])
                self.data[i][mask] = self.data[i-1][mask]
            # å‰©ä½™çš„NaNç”¨fill_valueå¡«å……
            self.data = np.nan_to_num(self.data, nan=self.fill_value)
                
        print(f"æ•°æ®çŸ©é˜µå½¢çŠ¶: {self.data.shape}")
        print(f"å¡«å……åç¼ºå¤±å€¼æ¯”ä¾‹: {np.isnan(self.data).mean():.3f}")
        
    def _build_graph_connectivity(self):
        """æ„å»ºåŸºäºèŠ‚ç‚¹è¿æ¥è§„åˆ™çš„å›¾è¿æ¥"""
        n_lanes = len(self.lane_ids)
        adj_matrix = np.zeros((n_lanes, n_lanes))
        
        # åˆ›å»ºlane_idåˆ°ç´¢å¼•çš„æ˜ å°„
        lane_id_to_idx = {lid: idx for idx, lid in enumerate(self.lane_ids)}
        
        # éå†é™æ€èŠ‚ç‚¹ï¼Œæ„å»ºé‚»æ¥çŸ©é˜µ
        for node in self.static_nodes:
            source_lane = node[self.lane_id_col]
            if source_lane not in lane_id_to_idx:
                continue
            source_idx = lane_id_to_idx[source_lane]
            
            # è·å–èŠ‚ç‚¹è¿æ¥ä¿¡æ¯
            connections = node.get('node_connections', {})
            if isinstance(connections, str):
                try:
                    connections = json.loads(connections)
                except:
                    connections = {}
            
            # å¤„ç†ä¸åŒç±»å‹çš„è¿æ¥
            for conn_type, targets in connections.items():
                if not isinstance(targets, list):
                    targets = [targets]
                
                for target_lane in targets:
                    if target_lane in lane_id_to_idx:
                        target_idx = lane_id_to_idx[target_lane]
                        
                        # æ ¹æ®è¿æ¥ç±»å‹è®¾ç½®æƒé‡
                        if conn_type == 'direct':
                            weight = 1.0
                        elif conn_type == 'near':
                            weight = 0.5
                        elif conn_type == 'crossing':
                            weight = 0.3
                        else:
                            weight = 0.1
                        
                        # æ·»åŠ åŒå‘è¿æ¥
                        adj_matrix[source_idx, target_idx] = max(adj_matrix[source_idx, target_idx], weight)
                        adj_matrix[target_idx, source_idx] = max(adj_matrix[target_idx, source_idx], weight)
        
        self.adjacency = adj_matrix
        print(f"å›¾è¿æ¥çŸ©é˜µå½¢çŠ¶: {self.adjacency.shape}")
        print(f"è¿æ¥æ•°: {np.sum(adj_matrix > 0) // 2}")
        
    def _create_masks(self):
        """åˆ›å»ºè®­ç»ƒ/è¯„ä¼°æ©ç ï¼ˆæ”¯æŒå¤šç»„maskæ–‡ä»¶ï¼‰"""
        n_times, n_lanes, n_features = self.data.shape
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ä»»ä½•maskæ–‡ä»¶
        has_masks = any(p is not None for p in self.mask_data_paths)
        
        if has_masks:
            self._load_user_masks()
            print(f"âœ… ä½¿ç”¨ç”¨æˆ·è‡ªå®šä¹‰æ©ç ")
            print(f"   å·²è§‚æµ‹æ•°æ®æ¯”ä¾‹: {self.training_mask.mean():.3f}")
            print(f"   æœªè§‚æµ‹æ•°æ®æ¯”ä¾‹: {self.eval_mask.mean():.3f}")
        else:
            # é»˜è®¤ï¼šæ‰€æœ‰æ•°æ®ç”¨äºè®­ç»ƒï¼Œéšæœºé€‰æ‹©20%ç”¨äºè¯„ä¼°
            self.training_mask = np.ones((n_times, n_lanes, n_features), dtype=bool)
            
            np.random.seed(42)
            eval_indices = np.random.choice(
                n_times * n_lanes * n_features,
                size=int(0.2 * n_times * n_lanes * n_features),
                replace=False
            )
            
            self.eval_mask = np.zeros((n_times, n_lanes, n_features), dtype=bool)
            eval_mask_flat = self.eval_mask.reshape(-1)
            eval_mask_flat[eval_indices] = True
            print(f"âœ… ä½¿ç”¨éšæœºç”Ÿæˆçš„æ©ç ")
            
    def _load_user_masks(self):
        """ä»ç”¨æˆ·æä¾›çš„å¤šä¸ªCSVæ–‡ä»¶åŠ è½½æ©ç æ•°æ®"""
        n_times, n_lanes, n_features = self.data.shape
        
        # åˆå§‹åŒ–æ©ç çŸ©é˜µï¼ˆé»˜è®¤æ‰€æœ‰ä½ç½®éƒ½æ˜¯æœªè§‚æµ‹çš„ï¼‰
        self.training_mask = np.zeros((n_times, n_lanes, n_features), dtype=bool)
        
        # åˆ›å»ºç´¢å¼•æ˜ å°„
        lane_id_to_idx = {lid: idx for idx, lid in enumerate(self.lane_ids)}
        time_to_idx = {t: idx for idx, t in enumerate(self.timestamps)}
        
        # åŠ è½½æ‰€æœ‰maskæ–‡ä»¶
        for i, mask_path in enumerate(self.mask_data_paths):
            if mask_path is None:
                continue
                
            mask_path = Path(mask_path)
            if not mask_path.exists():
                print(f"âš ï¸ è­¦å‘Š: æ©ç æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡: {mask_path}")
                continue
            
            print(f"   åŠ è½½æ©ç æ–‡ä»¶ {i+1}: {mask_path}")
            mask_df = pd.read_csv(mask_path)
            
            # æ£€æŸ¥å¿…éœ€åˆ—
            required_cols = [self.mask_time_col, self.mask_lane_col, self.mask_value_col]
            missing_cols = [col for col in required_cols if col not in mask_df.columns]
            if missing_cols:
                raise ValueError(f"æ©ç æ–‡ä»¶ {mask_path} ç¼ºå°‘å¿…éœ€åˆ—: {missing_cols}")
            
            # å¡«å……æ©ç 
            for _, row in mask_df.iterrows():
                time_val = row[self.mask_time_col]
                lane_id = row[self.mask_lane_col]
                is_observed = bool(row[self.mask_value_col])
                
                time_idx = time_to_idx.get(time_val)
                lane_idx = lane_id_to_idx.get(lane_id)
                
                if time_idx is not None and lane_idx is not None:
                    # å¯¹æ‰€æœ‰ç‰¹å¾éƒ½ä½¿ç”¨ç›¸åŒçš„æ©ç 
                    self.training_mask[time_idx, lane_idx, :] = is_observed
        
        # è¯„ä¼°æ©ç æ˜¯è®­ç»ƒæ©ç çš„å
        self.eval_mask = ~self.training_mask
        
    def get_connectivity(self, threshold: float = 0.1, 
                        include_self: bool = False,
                        force_symmetric: bool = True) -> np.ndarray:
        """è·å–å›¾è¿æ¥çŸ©é˜µ"""
        adj = self.adjacency.copy()
        
        # åº”ç”¨é˜ˆå€¼ï¼Œè½¬ä¸ºäºŒå€¼çŸ©é˜µ
        adj = (adj >= threshold).astype(np.uint8)
        
        if not include_self:
            np.fill_diagonal(adj, 0)
            
        if force_symmetric:
            adj = np.maximum(adj, adj.T)
            
        return adj
        
    def numpy(self, return_idx: bool = False) -> Union[Tuple, np.ndarray]:
        """è¿”å›numpyæ ¼å¼çš„æ•°æ®"""
        if return_idx:
            return self.data, self.timestamps, self.lane_ids
        return self.data
        
    def datetime_encoded(self, encoding: List[str]) -> pd.DataFrame:
        """è·å–æ—¶é—´ç¼–ç  - é€‚ç”¨äºçŸ­æ—¶é—´å°ºåº¦è¿ç»­æ•°æ®"""
        n_times = len(self.timestamps)
        df = pd.DataFrame(index=range(n_times))
        
        # å½’ä¸€åŒ–æ—¶é—´ä½ç½® [0, 1]
        t_min, t_max = self.timestamps.min(), self.timestamps.max()
        normalized_t = (self.timestamps - t_min) / (t_max - t_min + 1e-8)
        
        # çº¿æ€§æ—¶é—´ä½ç½®
        df['time_linear'] = normalized_t
        
        return df
        
    def get_splitter(self, val_len: float = None, test_len: float = None):
        """è·å–æ•°æ®åˆ†å‰²å™¨"""
        from tsl.data.datamodule.splitters import TemporalSplitter
        
        val_len = val_len or self.val_len
        test_len = test_len or self.test_len
        
        return TemporalSplitter(val_len=val_len, test_len=test_len)
        
    @property
    def n_nodes(self) -> int:
        """èŠ‚ç‚¹æ•°é‡"""
        return len(self.lane_ids)
        
    @property
    def n_channels(self) -> int:
        """ç‰¹å¾é€šé“æ•°"""
        return self.data.shape[-1]
        
    @property
    def length(self) -> int:
        """æ—¶é—´åºåˆ—é•¿åº¦"""
        return len(self.timestamps)
        
    def __len__(self) -> int:
        return self.length
        
    def __getitem__(self, idx: int) -> Dict[str, Any]:
        """è·å–å•ä¸ªæ—¶é—´æ­¥çš„æ•°æ®"""
        return {
            'data': self.data[idx],
            'timestamp': self.timestamps[idx],
            'lane_ids': self.lane_ids
        }
