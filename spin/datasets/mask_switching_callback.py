"""
Maskåˆ‡æ¢å›è°ƒï¼Œç”¨äºåœ¨è®­ç»ƒæ—¶æ¯ä¸ªepochæŒ‰é¡ºåºå¾ªç¯é€‰æ‹©ä¸åŒçš„maskæ–‡ä»¶
é¿å…å›ºå®šç¼ºå¤±æ¨¡å¼å½¢æˆç¡¬ç¼–ç å¼æ·å¾„ï¼ŒåŒæ—¶ç¡®ä¿æ¯ä¸ªmaskæ–‡ä»¶è¢«å‡åŒ€ä½¿ç”¨
"""

import pytorch_lightning as pl
from typing import Optional


class MaskSwitchingCallback(pl.Callback):
    """
    åœ¨æ¯ä¸ªè®­ç»ƒepochå¼€å§‹æ—¶æŒ‰é¡ºåºå¾ªç¯åˆ‡æ¢maskçš„å›è°ƒ
    
    ä½¿ç”¨æ–¹æ³•ï¼š
        from spin.datasets.mask_switching_callback import MaskSwitchingCallback
        
        callback = MaskSwitchingCallback(dataset, torch_dataset)
        trainer = pl.Trainer(callbacks=[callback, ...])
    """
    
    def __init__(self, dataset, torch_dataset):
        """
        åˆå§‹åŒ–å›è°ƒ
        
        Args:
            dataset: LaneTrafficDatasetå®ä¾‹
            torch_dataset: ImputationDatasetå®ä¾‹
        """
        super().__init__()
        self.dataset = dataset
        self.torch_dataset = torch_dataset
    
    def on_train_epoch_start(self, trainer: pl.Trainer, pl_module: pl.LightningModule) -> None:
        """åœ¨æ¯ä¸ªè®­ç»ƒepochå¼€å§‹æ—¶è°ƒç”¨"""
        # æ£€æŸ¥æ˜¯å¦æœ‰mask_filesåˆ—è¡¨
        if not self.dataset.mask_files:
            return
        
        # è·å–å½“å‰epochç¼–å·
        current_epoch = trainer.current_epoch
        
        # æŒ‰é¡ºåºå¾ªç¯åˆ‡æ¢maskï¼ˆä½¿ç”¨epochç¼–å·è¿›è¡Œå¾ªç¯é€‰æ‹©ï¼‰
        success = self.dataset.switch_mask_sequentially(epoch=current_epoch)
        
        if success:
            # æ›´æ–°torch_datasetçš„mask
            if hasattr(self.torch_dataset, 'set_mask'):
                self.torch_dataset.set_mask(self.dataset.training_mask)
            # æ›´æ–°exogenousä¸­çš„eval_mask
            if hasattr(self.torch_dataset, 'update_exogenous'):
                self.torch_dataset.update_exogenous('eval_mask', self.dataset.eval_mask)
            print(f"ğŸ“Š Epoch {current_epoch}: å·²åˆ‡æ¢åˆ°maskæ–‡ä»¶: {self.dataset.current_mask_file}")

